# ğŸ“˜ All Pairs Matching with PySpark

This project solves the **All Pairs Matching Problem** using two approaches: **naive pairs** and **group pairs matching**. Implemented in **Python** using **PySpark**, the system follows the **Map-Reduce model** to compute **Jaccard similarity** between users based on the movies they have rated.

The application runs inside a Dockerized Spark cluster, allowing controlled benchmarking across datasets of different sizes.

---

## ğŸ“„ Description

- What problem does this project solve?
- What approaches are implemented?
- What technologies are used?

---

## ğŸ“‚ Project Structure

    â”œâ”€â”€ docker-compose.yml # Defines the Spark cluster (1 master, 2 workers)
    â”œâ”€â”€ .env # Environment variables (mode and dataset size)
    â”œâ”€â”€ datasets/
    â”‚ â””â”€â”€ movies-ratings.csv # Movie ratings dataset
    â”œâ”€â”€ spark/
    â”‚ â”œâ”€â”€ Dockerfile # Docker setup for Spark nodes
    â”‚ â””â”€â”€ spark-env.sh # Spark environment variables
    â””â”€â”€ src/
    â”œâ”€â”€ main.py # Entrypoint that loads the selected matching mode
    â”œâ”€â”€ naive_runner.py # Naive matching implementation
    â”œâ”€â”€ group_runner.py # Group-based matching implementation
    â”œâ”€â”€ Dockerfile # Docker setup for the PySpark app
    â””â”€â”€ requirements.txt # Python dependencies (e.g., pyspark)

---

## âš™ï¸ Setup & Usage

### 1. Clone the Repository

```bash
  git clone https://github.com/your-username/all-pairs-matching.git
  cd all-pairs-matching
```

### 2. Configure Environment (edit .env file)

### 3.Run the Application
```bash
  docker-compose up --build
```

## ğŸ§  Problem Overview
Explain the All Pairs Matching Problem and how Jaccard similarity is used.

### ğŸ› ï¸ Approaches

### 1. ğŸ”¹ Naive Matching
Description
### 2. ğŸ”¹ Group-Based Matching
Description

## ğŸ§ª Input & Output

## ğŸ³ Dockerized Spark Cluster

## â±ï¸ Performance Benchmarking

## ğŸ“¦ Requirements

## ğŸ“„ License

## ğŸ‘¤ Author

